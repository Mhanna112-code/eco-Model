{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "finnish-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import pdb\n",
    "from heapq import heappush, heappop\n",
    "from auxiliary import ScaledEmbedding, ZeroEmbedding\n",
    "import evaluation\n",
    "import data_loader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "#from cpt.cpt import Cpt\n",
    "#from cpt import PT_LogSoftmax\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vulnerable-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "    params = dict()\n",
    "    params['lr'] = 1e-4\n",
    "    params['batch_size'] = 1\n",
    "    params['epoch_limit'] = 100\n",
    "    params['w_decay'] = 5e-4\n",
    "    params['negNum_test'] = 36\n",
    "    params['epsilon'] = 1e-4\n",
    "    params['negNum_train'] = 2\n",
    "    params['l_size'] = 128\n",
    "    params['train_device'] = 'cpu'\n",
    "    params['test_device'] = 'cpu'\n",
    "    params['lambda'] = 1\n",
    "    params['test_per_train'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "minus-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "    item_price = np.load(r\"C:\\\\Users\\march\\Risk-Aware-Recommnedation-Model\\data\\Movielens1M_item_price.npy\")\n",
    "    category1 = 'newTrainSamples'\n",
    "    category2 = 'newTestSamples'\n",
    "    catAll = 'AllSamples'\n",
    "    metaCat = 'Appliances'\n",
    "    \n",
    "    train, test = data_loader.read_data(category1, category2)\n",
    "    userNum, itemNum = data_loader.get_datasize(catAll)\n",
    "    data_loader.get_ecoScores(metaCat, catAll)\n",
    "    AllSamples = data_loader.read_AllSamples(catAll)\n",
    "    distribution = data_loader.get_itemDist(AllSamples, itemNum)\n",
    "    distribution = data_loader.approx_Gaussian(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "falling-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PT(nn.Module):\n",
    "    def __init__(self, userLen, itemLen, distribution, params, item_price):\n",
    "        super(PT, self).__init__()\n",
    "        self.userNum = userLen\n",
    "        self.itemNum = itemLen\n",
    "        self.params = params\n",
    "\n",
    "        if 'gpu' in params and params['gpu'] == True:\n",
    "            self.device = 'cuda'\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "\n",
    "        l_size = params['l_size']\n",
    "        self.distribution = torch.FloatTensor(distribution).to(self.device)\n",
    "        self.item_price = torch.FloatTensor(item_price).to(self.device)\n",
    "        self.globalBias_g = ZeroEmbedding(1, 1).to(self.device).to(torch.float)\n",
    "        self.globalBias_g.weight.data += 0.5\n",
    "        self.globalBias_g.weight.requires_grad = False\n",
    "        #self.ecoBias_g = ZeroEmbedding(itemLen, 1).to(self.device).to(torch.float)\n",
    "        self.userBias_g = ZeroEmbedding(userLen, 1).to(self.device).to(torch.float)\n",
    "        self.itemBias_g = ZeroEmbedding(itemLen, 1).to(self.device).to(torch.float)\n",
    "        self.userEmbed_g = ScaledEmbedding(userLen, l_size).to(self.device).to(torch.float)\n",
    "        #self.ecoEmbed_g = ScaledEmbedding(itemLen, l_size).to(self.device).to(torch.float)\n",
    "        self.itemEmbed_g = ScaledEmbedding(itemLen, l_size).to(self.device).to(torch.float)\n",
    "\n",
    "        self.globalBias_d = ZeroEmbedding(1, 1).to(self.device).to(torch.float)\n",
    "        self.globalBias_d.weight.data += 0.5\n",
    "        self.globalBias_d.weight.requires_grad = False\n",
    "        #self.ecoBias_d = ZeroEmbedding(itemLen, 1).to(self.device).to(torch.float)\n",
    "        self.userBias_d = ZeroEmbedding(userLen, 1).to(self.device).to(torch.float)\n",
    "        self.itemBias_d = ZeroEmbedding(itemLen, 1).to(self.device).to(torch.float)\n",
    "        self.userEmbed_d = ScaledEmbedding(userLen, l_size).to(self.device).to(torch.float)\n",
    "        #self.ecoEmbed_d = ScaledEmbedding(itemLen, l_size).to(self.device).to(torch.float)\n",
    "        self.itemEmbed_d = ScaledEmbedding(itemLen, l_size).to(self.device).to(torch.float)\n",
    "\n",
    "        self.globalBias_a = ZeroEmbedding(1, 1).to(self.device).to(torch.float)\n",
    "        self.globalBias_a.weight.requires_grad = False\n",
    "        self.userBias_a = ZeroEmbedding(userLen, 1).to(self.device).to(torch.float)\n",
    "        self.userBias_a.weight.data.uniform_(0.0, 0.05)\n",
    "        self.itemBias_a = ZeroEmbedding(itemLen, 1).to(self.device).to(torch.float)\n",
    "        self.ecoBias_a = ZeroEmbedding(itemLen, 1).to(self.device).to(torch.float)\n",
    "        self.itemBias_a.weight.data.uniform_(0.0, 0.05)\n",
    "        self.ecoBias_a.weight.data.uniform_(0.0, 0.05)\n",
    "        self.userEmbed_a = ZeroEmbedding(userLen, l_size).to(self.device).to(torch.float)\n",
    "        self.userEmbed_a.weight.data.uniform_(-0.01, 0.01)\n",
    "        self.itemEmbed_a = ZeroEmbedding(itemLen, l_size).to(self.device).to(torch.float)\n",
    "        self.itemEmbed_a.weight.data.uniform_(-0.01, 0.01)\n",
    "        self.ecoEmbed_a = ZeroEmbedding(itemLen, l_size).to(self.device).to(torch.float)\n",
    "        self.ecoEmbed_a.weight.data.uniform_(-0.01, 0.01)\n",
    "\n",
    "        self.globalBias_b = ZeroEmbedding(1, 1).to(self.device).to(torch.float)\n",
    "        self.globalBias_b.weight.requires_grad = False\n",
    "        self.userBias_b = ZeroEmbedding(userLen, 1).to(self.device).to(torch.float)\n",
    "        #self.ecoBias_b = ZeroEmbedding(itemLen, 1).to(self.device).to(torch.float)\n",
    "        self.userBias_b.weight.data.uniform_(0.0, 0.05)\n",
    "        #self.ecoBias_b.weight.data.uniform_(0.0, 0.05)\n",
    "        self.itemBias_b = ZeroEmbedding(itemLen, 1).to(self.device).to(torch.float)\n",
    "        self.itemBias_b.weight.data.uniform_(0.0, 0.05)\n",
    "        self.userEmbed_b = ZeroEmbedding(userLen, l_size).to(self.device).to(torch.float)\n",
    "        self.userEmbed_b.weight.data.uniform_(-0.01, 0.01)\n",
    "        self.itemEmbed_b = ZeroEmbedding(itemLen, l_size).to(self.device).to(torch.float)\n",
    "        self.itemEmbed_b.weight.data.uniform_(-0.01, 0.01)\n",
    "        #self.ecoEmbed_b = ZeroEmbedding(itemLen, l_size).to(self.device).to(torch.float)\n",
    "        self.itemEmbed_b.weight.data.uniform_(-0.01, 0.01)\n",
    "\n",
    "        #self.ecoEmbed_l = ZeroEmbedding(itemLen, l_size).to(self.device).to(torch.float)\n",
    "        self.globalBias_l = ZeroEmbedding(1, 1).to(self.device).to(torch.float)\n",
    "        self.globalBias_l.weight.data += 1\n",
    "        self.globalBias_l.weight.requires_grad = False\n",
    "        self.userBias_l = ZeroEmbedding(userLen, 1).to(self.device).to(torch.float)\n",
    "        self.userBias_l.weight.data.uniform_(0.0, 0.05)\n",
    "        self.itemBias_l = ZeroEmbedding(itemLen, 1).to(self.device).to(torch.float)\n",
    "        self.itemBias_l.weight.data.uniform_(0.0, 0.05)\n",
    "        #self.ecoBias_l = ZeroEmbedding(itemLen, 1).to(self.device).to(torch.float)\n",
    "        #self.ecoBias_l.weight.data.uniform_(0.0, 0.05)\n",
    "        self.userEmbed_l = ZeroEmbedding(userLen, l_size).to(self.device).to(torch.float)\n",
    "        self.userEmbed_l.weight.data.uniform_(-0.01, 0.01)\n",
    "        self.itemEmbed_l = ZeroEmbedding(itemLen, l_size).to(self.device).to(torch.float)\n",
    "        self.itemEmbed_l.weight.data.uniform_(-0.01, 0.01)\n",
    "        #self.ecoEmbed_l = ZeroEmbedding(itemLen, l_size).to(self.device).to(torch.float)\n",
    "        #self.ecoEmbed_l.weight.data.uniform_(-0.01, 0.01)\n",
    "\n",
    "        self.reference_point = ZeroEmbedding(userLen, 1).to(self.device).to(torch.float)\n",
    "        self.reference_point.weight.data = torch.ones_like(self.reference_point.weight.data) * 1.5\n",
    "        #\t\t self.reference_point.weight.requires_grad=False\n",
    "        self.to(self.device)\n",
    "        self.grads = {}\n",
    "        \n",
    "    def ecoForward(self, items):\n",
    "        ecoBias_a = self.ecoBias_a(items)\n",
    "        ecoEmbed_a = self.ecoEmbed_a(items)\n",
    "        itemEmbed_a = self.itemEmbed_a(items)\n",
    "\n",
    "        alpha = ecoBias_a + torch.mul(ecoEmbed_a, itemEmbed_a).sum(1).view(-1, 1)\n",
    "        return alpha\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        distribution = self.distribution[items].to(self.device)\n",
    "        reference_point = self.reference_point(users)\n",
    "        #\t\t print(users.shape[0],items.shape[0])\n",
    "        price = self.item_price[items].view(-1, 1).expand(users.shape[0], 5).to(self.device)\n",
    "\n",
    "        # calculate value\n",
    "        globalBias_a = self.globalBias_a(torch.tensor(0).to(self.device))\n",
    "        userBias_a = self.userBias_a(users)\n",
    "        itemBias_a = self.itemBias_a(items)\n",
    "        userEmbed_a = self.userEmbed_a(users)\n",
    "        itemEmbed_a = self.itemEmbed_a(items)\n",
    "\n",
    "        globalBias_b = self.globalBias_b(torch.tensor(0).to(self.device))\n",
    "        userBias_b = self.userBias_b(users)\n",
    "        itemBias_b = self.itemBias_b(items)\n",
    "        userEmbed_b = self.userEmbed_b(users)\n",
    "        itemEmbed_b = self.itemEmbed_b(items)\n",
    "\n",
    "        globalBias_l = self.globalBias_l(torch.tensor(0).to(self.device))\n",
    "        userBias_l = self.userBias_l(users)\n",
    "        itemBias_l = self.itemBias_l(items)\n",
    "        userEmbed_l = self.userEmbed_l(users)\n",
    "        itemEmbed_l = self.itemEmbed_l(items)\n",
    "\n",
    "        alpha = globalBias_a + userBias_a + itemBias_a + torch.mul(userEmbed_a, itemEmbed_a).sum(1).view(-1, 1)\n",
    "        beta = globalBias_b + userBias_b + itemBias_b + torch.mul(userEmbed_b, itemEmbed_b).sum(1).view(-1, 1)\n",
    "        lamda = globalBias_l + userBias_l + itemBias_l + torch.mul(userEmbed_l, itemEmbed_l).sum(1).view(-1, 1)\n",
    "\n",
    "        rating = torch.tensor([1., 2., 3., 4., 5.]).expand(users.shape[0], 5).to(self.device)\n",
    "        x = torch.tanh(rating - reference_point)\n",
    "        x_binary_pos = torch.gt(x, torch.FloatTensor([0]).to(self.device)).to(torch.float)\n",
    "        x_binary_neg = torch.ones_like(x).to(self.device) - x_binary_pos\n",
    "\n",
    "        x_ = torch.mul(price, torch.abs(x))\n",
    "        v_exp = torch.mul(alpha, x_binary_pos) + torch.mul(beta, x_binary_neg)\n",
    "        v = x_.pow(v_exp)\n",
    "        v_coef = x_binary_pos - torch.mul(lamda, x_binary_neg)\n",
    "        value = torch.mul(v, v_coef).to(self.device)\n",
    "\n",
    "        # calculate weight\n",
    "        globalBias_g = self.globalBias_g(torch.tensor(0).to(self.device))\n",
    "        userBias_g = self.userBias_g(users)\n",
    "        itemBias_g = self.itemBias_g(items)\n",
    "        userEmbed_g = self.userEmbed_g(users)\n",
    "        itemEmbed_g = self.itemEmbed_g(items)\n",
    "\n",
    "        globalBias_d = self.globalBias_d(torch.tensor(0).to(self.device))\n",
    "        userBias_d = self.userBias_d(users)\n",
    "        itemBias_d = self.itemBias_d(items)\n",
    "        userEmbed_d = self.userEmbed_d(users)\n",
    "        itemEmbed_d = self.itemEmbed_d(items)\n",
    "\n",
    "        gamma = globalBias_g + userBias_g + itemBias_g + torch.mul(userEmbed_g, itemEmbed_g).sum(1).view(-1, 1)\n",
    "        delta = globalBias_d + userBias_d + itemBias_d + torch.mul(userEmbed_d, itemEmbed_d).sum(1).view(-1, 1)\n",
    "\n",
    "        gamma_ = gamma.expand(users.shape[0], 5)\n",
    "        delta_ = delta.expand(users.shape[0], 5)\n",
    "        w_exp = torch.mul(x_binary_pos, gamma_) + torch.mul(x_binary_neg, delta_)\n",
    "\n",
    "        w_nominator = distribution.pow(w_exp)\n",
    "        w_denominator = (distribution.pow(w_exp) + (torch.ones_like(distribution).to(self.device) - distribution).pow(\n",
    "            w_exp)).pow(1 / w_exp)\n",
    "        weight = torch.div(w_nominator, w_denominator)\n",
    "\n",
    "        #\t\t self.userBias_g.weight.register_hook(self.save_grad('userBias_g'))\n",
    "        #\t\t self.itemBias_g.weight.register_hook(self.save_grad('itemBias_g'))\n",
    "        #\t\t self.userEmbed_g.weight.register_hook(self.save_grad('userEmbed_g'))\n",
    "        #\t\t self.itemEmbed_g.weight.register_hook(self.save_grad('itemEmbed_g'))\n",
    "        return torch.mul(weight, value).sum(1)\n",
    "    \n",
    "    def loss(self, users, items, negItems):\n",
    "        nusers = users.view(-1, 1).to(self.device)\n",
    "        nusers = nusers.expand(nusers.shape[0], self.params['negNum_train']).reshape(-1).to(self.device)\n",
    "\n",
    "        pOut = self.forward(users, items).view(-1, 1)#.expand(users.shape[0], self.params['negNum_train']).reshape(-1, 1)\n",
    "        nOut = self.forward(nusers, negItems).reshape(-1, self.params['negNum_train'])\n",
    "        Out = torch.cat((pOut,nOut),dim=1)\n",
    "        \n",
    "#         print(Out.shape)\n",
    "#         print(nOut.shape)\n",
    "#         input()\n",
    "        criterion = nn.LogSoftmax(dim=1)\n",
    "        res = criterion(Out)[:,0]\n",
    "        loss = torch.mean(res)\n",
    "        neg = data_loader.get_env_neg(items, self.params['negNum_train'])\n",
    "        for j in data_loader.items:\n",
    "            if data_loader.items[j][1] == items and data_loader.items[j][0] == 1:\n",
    "                env = 1\n",
    "                break\n",
    "            elif data_loader.items[j][1] == items and data_loader.items[j][0] == 0:\n",
    "                env = 0\n",
    "                break\n",
    "        for n in range(len(neg)):\n",
    "            neg[n] = neg[n][1]\n",
    "        if env == 1:\n",
    "            Out = torch.cat((pOut, self.ecoForward(torch.tensor(neg)).reshape(-1, self.params['negNum_train'])), dim=1)\n",
    "            res = criterion(Out)[:, 0]\n",
    "            loss += torch.mean(res)\n",
    "        else:\n",
    "            Out = -torch.cat((pOut, self.ecoForward(torch.tensor(neg)).reshape(-1, self.params['negNum_train'])), dim=1)\n",
    "            res = criterion(Out)[:, 0]\n",
    "            loss += torch.mean(res)\n",
    "        return -loss\n",
    "\n",
    "    def get_grads(self):\n",
    "        return self.grads\n",
    "\n",
    "    def save_grad(self, name):\n",
    "        def hook(grad):\n",
    "            self.grads[name] = grad\n",
    "        return hook\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "executed-attraction",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "Epoch  1  training...\n",
      "processed: 1: 100%|██████████████████████████████████████████████████████████████████| 740/740 [00:16<00:00, 45.43it/s]\n",
      "epoch loss tensor(1512.2292, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:16<00:00, 10.96it/s]\n",
      "\tPrecision@: {1:0.010810810810810811; 5: 0.0291891891891892; 10: 0.032432432432432406; 20: 0.029459459459459398}\n",
      "\tRecall@: {1:0.010810810810810811; 5: 0.14594594594594595; 10: 0.32432432432432434; 20: 0.5891891891891892}\n",
      "\tF1@: {1:0.010810810810810811; 5: 0.04864864864864866; 10: 0.05896805896805892; 20: 0.056113256113256}\n",
      "\tNDCG@: {1:0.010810810810810811; 5: 0.08523717991013467; 10: 0.1467858782008446; 20: 0.21431651872423452}\n",
      "\tPrecision@: {1:0.8540540540540541; 5: 0.9405405405405407; 10: 0.8778378378378388; 20: 0.6948648648648649}\n",
      "\tRecall@: {1:0.8540540540540541; 5: 4.702702702702703; 10: 8.778378378378378; 20: 13.897297297297298}\n",
      "\tF1@: {1:0.854054054054054; 5: 1.5675675675675678; 10: 1.5960687960687976; 20: 1.3235521235521235}\n",
      "\tNDCG@: {1:0.8540540540540541; 5: 3.3384516403481417; 10: 4.722931674693366; 20: 6.041908474806597}\n",
      "Epoch  2  training...\n",
      "processed: 2: 100%|██████████████████████████████████████████████████████████████████| 740/740 [00:22<00:00, 33.15it/s]\n",
      "epoch loss tensor(1161.8702, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:13<00:00, 13.23it/s]\n",
      "\tPrecision@: {1:0.005405405405405406; 5: 0.025945945945945955; 10: 0.03621621621621617; 20: 0.030540540540540475}\n",
      "\tRecall@: {1:0.005405405405405406; 5: 0.12972972972972974; 10: 0.3621621621621622; 20: 0.6108108108108108}\n",
      "\tF1@: {1:0.005405405405405406; 5: 0.04324324324324326; 10: 0.06584766584766578; 20: 0.05817245817245805}\n",
      "\tNDCG@: {1:0.005405405405405406; 5: 0.08037642091821139; 10: 0.1613254335589785; 20: 0.22381177251708836}\n",
      "\tPrecision@: {1:0.8918918918918919; 5: 0.9740540540540543; 10: 0.8924324324324335; 20: 0.6970270270270272}\n",
      "\tRecall@: {1:0.8918918918918919; 5: 4.870270270270271; 10: 8.924324324324324; 20: 13.94054054054054}\n",
      "\tF1@: {1:0.8918918918918918; 5: 1.623423423423424; 10: 1.6226044226044243; 20: 1.327670527670528}\n",
      "\tNDCG@: {1:0.8918918918918919; 5: 3.4434368353413385; 10: 4.8290487528765045; 20: 6.127502294106644}\n",
      "Epoch  3  training...\n",
      "processed: 3: 100%|██████████████████████████████████████████████████████████████████| 740/740 [00:42<00:00, 17.47it/s]\n",
      "epoch loss tensor(968.0210, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:16<00:00, 11.38it/s]\n",
      "\tPrecision@: {1:0.010810810810810811; 5: 0.0291891891891892; 10: 0.036756756756756714; 20: 0.030810810810810746}\n",
      "\tRecall@: {1:0.010810810810810811; 5: 0.14594594594594595; 10: 0.3675675675675676; 20: 0.6162162162162163}\n",
      "\tF1@: {1:0.010810810810810811; 5: 0.04864864864864866; 10: 0.06683046683046676; 20: 0.05868725868725856}\n",
      "\tNDCG@: {1:0.010810810810810811; 5: 0.09031642134713722; 10: 0.16587509347996604; 20: 0.23002079516221477}\n",
      "\tPrecision@: {1:0.8648648648648649; 5: 0.9697297297297296; 10: 0.9091891891891902; 20: 0.6883783783783785}\n",
      "\tRecall@: {1:0.8648648648648649; 5: 4.848648648648648; 10: 9.091891891891892; 20: 13.767567567567568}\n",
      "\tF1@: {1:0.8648648648648649; 5: 1.6162162162162161; 10: 1.6530712530712548; 20: 1.3111969111969115}\n",
      "\tNDCG@: {1:0.8648648648648649; 5: 3.419112511017014; 10: 4.866349227396571; 20: 6.063110895547411}\n",
      "Epoch  4  training...\n",
      "processed: 4: 100%|██████████████████████████████████████████████████████████████████| 740/740 [00:40<00:00, 18.14it/s]\n",
      "epoch loss tensor(897.4626, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:14<00:00, 13.17it/s]\n",
      "\tPrecision@: {1:0.005405405405405406; 5: 0.022702702702702707; 10: 0.03567567567567564; 20: 0.029999999999999936}\n",
      "\tRecall@: {1:0.005405405405405406; 5: 0.11351351351351352; 10: 0.3567567567567568; 20: 0.6}\n",
      "\tF1@: {1:0.005405405405405406; 5: 0.03783783783783785; 10: 0.0648648648648648; 20: 0.05714285714285703}\n",
      "\tNDCG@: {1:0.005405405405405406; 5: 0.06440671512167503; 10: 0.1462161507821963; 20: 0.20962626411208912}\n",
      "\tPrecision@: {1:0.8648648648648649; 5: 0.9470270270270272; 10: 0.865945945945947; 20: 0.691891891891892}\n",
      "\tRecall@: {1:0.8648648648648649; 5: 4.735135135135135; 10: 8.659459459459459; 20: 13.837837837837839}\n",
      "\tF1@: {1:0.8648648648648649; 5: 1.5783783783783785; 10: 1.5744471744471762; 20: 1.317889317889318}\n",
      "\tNDCG@: {1:0.8648648648648649; 5: 3.360031547752024; 10: 4.698674654956247; 20: 6.030937137293994}\n",
      "Epoch  5  training...\n",
      "processed: 5: 100%|██████████████████████████████████████████████████████████████████| 740/740 [00:39<00:00, 18.57it/s]\n",
      "epoch loss tensor(872.2402, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:14<00:00, 13.10it/s]\n",
      "\tPrecision@: {1:0.0; 5: 0.030270270270270284; 10: 0.03567567567567564; 20: 0.031081081081081013}\n",
      "\tRecall@: {1:0.0; 5: 0.15135135135135136; 10: 0.3567567567567568; 20: 0.6216216216216216}\n",
      "\tF1@: {1:0.0; 5: 0.050450450450450476; 10: 0.0648648648648648; 20: 0.05920205920205908}\n",
      "\tNDCG@: {1:0.0; 5: 0.09027470712939799; 10: 0.1579302192523713; 20: 0.22738965560199134}\n",
      "\tPrecision@: {1:0.8594594594594595; 5: 0.8648648648648646; 10: 0.7772972972972977; 20: 0.6791891891891894}\n",
      "\tRecall@: {1:0.8594594594594595; 5: 4.324324324324325; 10: 7.772972972972973; 20: 13.583783783783783}\n",
      "\tF1@: {1:0.8594594594594595; 5: 1.441441441441441; 10: 1.413267813267814; 20: 1.2936936936936938}\n",
      "\tNDCG@: {1:0.8594594594594595; 5: 3.1408675317173116; 10: 4.311303831141668; 20: 5.797438604141468}\n",
      "Epoch  6  training...\n",
      "processed: 6:   0%|                                                                            | 0/740 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\march\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\\evaluation.py:75: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  F1 = 2 / (1 / avgPrec + 1 / avgRecall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 6: 100%|██████████████████████████████████████████████████████████████████| 740/740 [00:41<00:00, 17.95it/s]\n",
      "epoch loss tensor(858.5729, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:18<00:00,  9.83it/s]\n",
      "\tPrecision@: {1:0.005405405405405406; 5: 0.030270270270270284; 10: 0.035135135135135095; 20: 0.031081081081081013}\n",
      "\tRecall@: {1:0.005405405405405406; 5: 0.15135135135135136; 10: 0.35135135135135137; 20: 0.6216216216216216}\n",
      "\tF1@: {1:0.005405405405405406; 5: 0.050450450450450476; 10: 0.06388206388206381; 20: 0.05920205920205908}\n",
      "\tNDCG@: {1:0.005405405405405406; 5: 0.09189496012670575; 10: 0.15731781227078778; 20: 0.228440472969962}\n",
      "\tPrecision@: {1:0.7945945945945946; 5: 0.8075675675675674; 10: 0.7459459459459461; 20: 0.6762162162162162}\n",
      "\tRecall@: {1:0.7945945945945946; 5: 4.037837837837838; 10: 7.45945945945946; 20: 13.524324324324324}\n",
      "\tF1@: {1:0.7945945945945946; 5: 1.3459459459459457; 10: 1.3562653562653566; 20: 1.288030888030888}\n",
      "\tNDCG@: {1:0.7945945945945946; 5: 2.9513460420900985; 10: 4.1060074404638955; 20: 5.660618157795867}\n",
      "Epoch  7  training...\n",
      "processed: 7: 100%|██████████████████████████████████████████████████████████████████| 740/740 [00:45<00:00, 16.09it/s]\n",
      "epoch loss tensor(847.0851, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.78it/s]\n",
      "\tPrecision@: {1:0.0; 5: 0.02486486486486487; 10: 0.031891891891891865; 20: 0.03243243243243236}\n",
      "\tRecall@: {1:0.0; 5: 0.12432432432432433; 10: 0.31891891891891894; 20: 0.6486486486486487}\n",
      "\tF1@: {1:0.0; 5: 0.041441441441441455; 10: 0.05798525798525793; 20: 0.06177606177606164}\n",
      "\tNDCG@: {1:0.0; 5: 0.07135578821047907; 10: 0.13588120305121953; 20: 0.2226809018931424}\n",
      "\tPrecision@: {1:0.8486486486486486; 5: 0.8086486486486482; 10: 0.7518918918918919; 20: 0.6762162162162163}\n",
      "\tRecall@: {1:0.8486486486486486; 5: 4.043243243243243; 10: 7.518918918918919; 20: 13.524324324324324}\n",
      "\tF1@: {1:0.8486486486486486; 5: 1.347747747747747; 10: 1.367076167076167; 20: 1.2880308880308882}\n",
      "\tNDCG@: {1:0.8486486486486486; 5: 2.9728326097021167; 10: 4.148339511400605; 20: 5.686584563406089}\n",
      "Epoch  8  training...\n",
      "  0%|                                                                                          | 0/740 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\march\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\\evaluation.py:75: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  F1 = 2 / (1 / avgPrec + 1 / avgRecall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 8: 100%|██████████████████████████████████████████████████████████████████| 740/740 [00:46<00:00, 16.00it/s]\n",
      "epoch loss tensor(859.2688, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:16<00:00, 11.44it/s]\n",
      "\tPrecision@: {1:0.005405405405405406; 5: 0.019459459459459465; 10: 0.028648648648648634; 20: 0.033513513513513435}\n",
      "\tRecall@: {1:0.005405405405405406; 5: 0.0972972972972973; 10: 0.2864864864864865; 20: 0.6702702702702703}\n",
      "\tF1@: {1:0.005405405405405406; 5: 0.03243243243243244; 10: 0.05208845208845207; 20: 0.0638352638352637}\n",
      "\tNDCG@: {1:0.005405405405405406; 5: 0.057714063808934034; 10: 0.12215517370800465; 20: 0.22392430456034185}\n",
      "\tPrecision@: {1:0.8378378378378378; 5: 0.7481081081081074; 10: 0.715675675675676; 20: 0.6729729729729733}\n",
      "\tRecall@: {1:0.8378378378378378; 5: 3.7405405405405405; 10: 7.1567567567567565; 20: 13.45945945945946}\n",
      "\tF1@: {1:0.8378378378378378; 5: 1.2468468468468457; 10: 1.3012285012285019; 20: 1.2818532818532826}\n",
      "\tNDCG@: {1:0.8378378378378378; 5: 2.771497513107417; 10: 3.9310978105461043; 20: 5.553429274001826}\n",
      "Epoch  9  training...\n",
      "processed: 9: 100%|██████████████████████████████████████████████████████████████████| 740/740 [00:44<00:00, 16.70it/s]\n",
      "epoch loss tensor(867.5195, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:17<00:00, 10.40it/s]\n",
      "\tPrecision@: {1:0.005405405405405406; 5: 0.022702702702702707; 10: 0.03459459459459456; 20: 0.033513513513513435}\n",
      "\tRecall@: {1:0.005405405405405406; 5: 0.11351351351351352; 10: 0.34594594594594597; 20: 0.6702702702702703}\n",
      "\tF1@: {1:0.005405405405405406; 5: 0.03783783783783785; 10: 0.06289926289926284; 20: 0.0638352638352637}\n",
      "\tNDCG@: {1:0.005405405405405406; 5: 0.07160229863015893; 10: 0.14990407834225186; 20: 0.23507199545783483}\n",
      "\tPrecision@: {1:0.7621621621621621; 5: 0.7340540540540533; 10: 0.708108108108108; 20: 0.6805405405405407}\n",
      "\tRecall@: {1:0.7621621621621621; 5: 3.67027027027027; 10: 7.081081081081081; 20: 13.610810810810811}\n",
      "\tF1@: {1:0.7621621621621621; 5: 1.2234234234234225; 10: 1.2874692874692872; 20: 1.2962676962676967}\n",
      "\tNDCG@: {1:0.7621621621621621; 5: 2.6589624914991115; 10: 3.809909855668918; 20: 5.485270298663216}\n",
      "Epoch  10  training...\n",
      "processed: 10: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:43<00:00, 17.17it/s]\n",
      "epoch loss tensor(871.1472, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:14<00:00, 12.91it/s]\n",
      "\tPrecision@: {1:0.005405405405405406; 5: 0.01837837837837838; 10: 0.024324324324324326; 20: 0.034324324324324244}\n",
      "\tRecall@: {1:0.005405405405405406; 5: 0.0918918918918919; 10: 0.24324324324324326; 20: 0.6864864864864865}\n",
      "\tF1@: {1:0.005405405405405406; 5: 0.030630630630630637; 10: 0.04422604422604423; 20: 0.06537966537966523}\n",
      "\tNDCG@: {1:0.005405405405405406; 5: 0.06349419052205083; 10: 0.11478657275062243; 20: 0.23026324862822725}\n",
      "\tPrecision@: {1:0.8; 5: 0.7416216216216205; 10: 0.7145945945945947; 20: 0.6832432432432435}\n",
      "\tRecall@: {1:0.8; 5: 3.708108108108108; 10: 7.145945945945946; 20: 13.664864864864866}\n",
      "\tF1@: {1:0.8; 5: 1.2360360360360345; 10: 1.2992628992628994; 20: 1.3014157014157017}\n",
      "\tNDCG@: {1:0.8; 5: 2.701723331911322; 10: 3.865451525121613; 20: 5.5348015074359775}\n",
      "Epoch  11  training...\n",
      "processed: 11: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:43<00:00, 16.84it/s]\n",
      "epoch loss tensor(868.9345, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:14<00:00, 13.19it/s]\n",
      "\tPrecision@: {1:0.016216216216216217; 5: 0.01837837837837838; 10: 0.03135135135135133; 20: 0.03270270270270263}\n",
      "\tRecall@: {1:0.016216216216216217; 5: 0.0918918918918919; 10: 0.31351351351351353; 20: 0.654054054054054}\n",
      "\tF1@: {1:0.016216216216216217; 5: 0.030630630630630637; 10: 0.05700245700245697; 20: 0.06229086229086217}\n",
      "\tNDCG@: {1:0.016216216216216217; 5: 0.06224865883245446; 10: 0.13654524486066125; 20: 0.2263253525897796}\n",
      "\tPrecision@: {1:0.7567567567567568; 5: 0.7416216216216208; 10: 0.7037837837837836; 20: 0.6854054054054054}\n",
      "\tRecall@: {1:0.7567567567567568; 5: 3.708108108108108; 10: 7.037837837837838; 20: 13.708108108108108}\n",
      "\tF1@: {1:0.7567567567567568; 5: 1.236036036036035; 10: 1.2796068796068794; 20: 1.3055341055341054}\n",
      "\tNDCG@: {1:0.7567567567567568; 5: 2.682835509201815; 10: 3.80324247154953; 20: 5.512374679947314}\n",
      "Epoch  12  training...\n",
      "processed: 12: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:45<00:00, 16.17it/s]\n",
      "epoch loss tensor(856.4395, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:17<00:00, 10.78it/s]\n",
      "\tPrecision@: {1:0.016216216216216217; 5: 0.02378378378378379; 10: 0.028648648648648634; 20: 0.03324324324324317}\n",
      "\tRecall@: {1:0.016216216216216217; 5: 0.11891891891891893; 10: 0.2864864864864865; 20: 0.6648648648648648}\n",
      "\tF1@: {1:0.016216216216216217; 5: 0.03963963963963965; 10: 0.05208845208845207; 20: 0.06332046332046318}\n",
      "\tNDCG@: {1:0.016216216216216217; 5: 0.07896096412284427; 10: 0.13587915475639362; 20: 0.23590686601456107}\n",
      "\tPrecision@: {1:0.745945945945946; 5: 0.7383783783783776; 10: 0.7059459459459462; 20: 0.6851351351351349}\n",
      "\tRecall@: {1:0.745945945945946; 5: 3.691891891891892; 10: 7.059459459459459; 20: 13.702702702702704}\n",
      "\tF1@: {1:0.745945945945946; 5: 1.2306306306306296; 10: 1.2835380835380839; 20: 1.3050193050193046}\n",
      "\tNDCG@: {1:0.745945945945946; 5: 2.6892922681032014; 10: 3.8241195260257417; 20: 5.524817883390732}\n",
      "Epoch  13  training...\n",
      "processed: 13: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:52<00:00, 14.09it/s]\n",
      "epoch loss tensor(866.1378, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:20<00:00,  9.18it/s]\n",
      "\tPrecision@: {1:0.016216216216216217; 5: 0.016216216216216217; 10: 0.028648648648648634; 20: 0.03243243243243236}\n",
      "\tRecall@: {1:0.016216216216216217; 5: 0.08108108108108109; 10: 0.2864864864864865; 20: 0.6486486486486487}\n",
      "\tF1@: {1:0.016216216216216217; 5: 0.02702702702702703; 10: 0.05208845208845207; 20: 0.06177606177606164}\n",
      "\tNDCG@: {1:0.016216216216216217; 5: 0.0615409304347709; 10: 0.13062528356078962; 20: 0.22643731638201983}\n",
      "\tPrecision@: {1:0.8324324324324325; 5: 0.745945945945945; 10: 0.7291891891891887; 20: 0.6932432432432433}\n",
      "\tRecall@: {1:0.8324324324324325; 5: 3.72972972972973; 10: 7.291891891891892; 20: 13.864864864864865}\n",
      "\tF1@: {1:0.8324324324324325; 5: 1.2432432432432419; 10: 1.325798525798525; 20: 1.3204633204633205}\n",
      "\tNDCG@: {1:0.8324324324324325; 5: 2.7629630581174762; 10: 3.9660926738688964; 20: 5.650815586285054}\n",
      "Epoch  14  training...\n",
      "processed: 14: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:53<00:00, 13.92it/s]\n",
      "epoch loss tensor(843.9648, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.66it/s]\n",
      "\tPrecision@: {1:0.010810810810810811; 5: 0.025945945945945955; 10: 0.03135135135135133; 20: 0.0329729729729729}\n",
      "\tRecall@: {1:0.010810810810810811; 5: 0.12972972972972974; 10: 0.31351351351351353; 20: 0.6594594594594595}\n",
      "\tF1@: {1:0.010810810810810811; 5: 0.04324324324324326; 10: 0.05700245700245697; 20: 0.06280566280566267}\n",
      "\tNDCG@: {1:0.010810810810810811; 5: 0.08370035534830533; 10: 0.14688269981732607; 20: 0.2380772391835555}\n",
      "\tPrecision@: {1:0.6918918918918919; 5: 0.7081081081081072; 10: 0.694054054054054; 20: 0.6791891891891892}\n",
      "\tRecall@: {1:0.6918918918918919; 5: 3.5405405405405403; 10: 6.940540540540541; 20: 13.583783783783783}\n",
      "\tF1@: {1:0.6918918918918919; 5: 1.180180180180179; 10: 1.2619164619164618; 20: 1.2936936936936938}\n",
      "\tNDCG@: {1:0.6918918918918919; 5: 2.5831411949691296; 10: 3.7314697265088386; 20: 5.435792916000979}\n",
      "Epoch  15  training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 15: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:47<00:00, 15.67it/s]\n",
      "epoch loss tensor(838.1364, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.71it/s]\n",
      "\tPrecision@: {1:0.021621621621621623; 5: 0.027027027027027035; 10: 0.02594594594594594; 20: 0.03459459459459451}\n",
      "\tRecall@: {1:0.021621621621621623; 5: 0.13513513513513514; 10: 0.2594594594594595; 20: 0.6918918918918919}\n",
      "\tF1@: {1:0.021621621621621623; 5: 0.045045045045045064; 10: 0.04717444717444717; 20: 0.06589446589446575}\n",
      "\tNDCG@: {1:0.021621621621621623; 5: 0.0881098077186081; 10: 0.13059421117901526; 20: 0.24369350609332974}\n",
      "\tPrecision@: {1:0.772972972972973; 5: 0.7502702702702696; 10: 0.7162162162162162; 20: 0.6905405405405406}\n",
      "\tRecall@: {1:0.772972972972973; 5: 3.7513513513513512; 10: 7.162162162162162; 20: 13.81081081081081}\n",
      "\tF1@: {1:0.772972972972973; 5: 1.2504504504504494; 10: 1.3022113022113022; 20: 1.3153153153153154}\n",
      "\tNDCG@: {1:0.772972972972973; 5: 2.7272446305859326; 10: 3.8789453644938545; 20: 5.583267437231413}\n",
      "Epoch  16  training...\n",
      "processed: 16: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:47<00:00, 15.70it/s]\n",
      "epoch loss tensor(830.9426, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.59it/s]\n",
      "\tPrecision@: {1:0.016216216216216217; 5: 0.022702702702702707; 10: 0.030810810810810788; 20: 0.0329729729729729}\n",
      "\tRecall@: {1:0.016216216216216217; 5: 0.11351351351351352; 10: 0.3081081081081081; 20: 0.6594594594594595}\n",
      "\tF1@: {1:0.016216216216216217; 5: 0.03783783783783785; 10: 0.05601965601965598; 20: 0.06280566280566267}\n",
      "\tNDCG@: {1:0.016216216216216217; 5: 0.08403336243827751; 10: 0.1487928564323436; 20: 0.24101108949189945}\n",
      "\tPrecision@: {1:0.7351351351351352; 5: 0.732972972972972; 10: 0.7081081081081078; 20: 0.6864864864864868}\n",
      "\tRecall@: {1:0.7351351351351352; 5: 3.6648648648648647; 10: 7.081081081081081; 20: 13.72972972972973}\n",
      "\tF1@: {1:0.7351351351351352; 5: 1.2216216216216205; 10: 1.287469287469287; 20: 1.307593307593308}\n",
      "\tNDCG@: {1:0.7351351351351352; 5: 2.671663663326432; 10: 3.821682854466535; 20: 5.526434204986715}\n",
      "Epoch  17  training...\n",
      "processed: 17: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:48<00:00, 15.30it/s]\n",
      "epoch loss tensor(828.1960, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:14<00:00, 12.34it/s]\n",
      "\tPrecision@: {1:0.0; 5: 0.01837837837837838; 10: 0.03135135135135133; 20: 0.03324324324324317}\n",
      "\tRecall@: {1:0.0; 5: 0.0918918918918919; 10: 0.31351351351351353; 20: 0.6648648648648648}\n",
      "\tF1@: {1:0.0; 5: 0.030630630630630637; 10: 0.05700245700245697; 20: 0.06332046332046318}\n",
      "\tNDCG@: {1:0.0; 5: 0.06278646212436727; 10: 0.1387495748294916; 20: 0.23071276934496812}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\march\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\\evaluation.py:75: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  F1 = 2 / (1 / avgPrec + 1 / avgRecall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPrecision@: {1:0.7513513513513513; 5: 0.6962162162162151; 10: 0.702162162162162; 20: 0.6808108108108109}\n",
      "\tRecall@: {1:0.7513513513513513; 5: 3.481081081081081; 10: 7.021621621621621; 20: 13.616216216216216}\n",
      "\tF1@: {1:0.7513513513513513; 5: 1.1603603603603587; 10: 1.2766584766584763; 20: 1.2967824967824968}\n",
      "\tNDCG@: {1:0.7513513513513513; 5: 2.573114697869913; 10: 3.768661933938638; 20: 5.453171939435964}\n",
      "Epoch  18  training...\n",
      "processed: 18: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:47<00:00, 15.67it/s]\n",
      "epoch loss tensor(822.1462, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:14<00:00, 12.56it/s]\n",
      "\tPrecision@: {1:0.021621621621621623; 5: 0.02486486486486487; 10: 0.030810810810810788; 20: 0.0329729729729729}\n",
      "\tRecall@: {1:0.021621621621621623; 5: 0.12432432432432433; 10: 0.3081081081081081; 20: 0.6594594594594595}\n",
      "\tF1@: {1:0.021621621621621623; 5: 0.041441441441441455; 10: 0.05601965601965598; 20: 0.06280566280566267}\n",
      "\tNDCG@: {1:0.021621621621621623; 5: 0.07712907180202654; 10: 0.13756998328147146; 20: 0.2306432797457436}\n",
      "\tPrecision@: {1:0.745945945945946; 5: 0.7189189189189177; 10: 0.6972972972972968; 20: 0.6802702702702706}\n",
      "\tRecall@: {1:0.745945945945946; 5: 3.5945945945945947; 10: 6.972972972972973; 20: 13.605405405405405}\n",
      "\tF1@: {1:0.745945945945946; 5: 1.1981981981981964; 10: 1.267813267813267; 20: 1.2957528957528965}\n",
      "\tNDCG@: {1:0.745945945945946; 5: 2.648367094898569; 10: 3.7883873284567673; 20: 5.485481972480962}\n",
      "Epoch  19  training...\n",
      "processed: 19: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:45<00:00, 16.22it/s]\n",
      "epoch loss tensor(816.4155, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 12.20it/s]\n",
      "\tPrecision@: {1:0.016216216216216217; 5: 0.02378378378378379; 10: 0.030810810810810788; 20: 0.033513513513513435}\n",
      "\tRecall@: {1:0.016216216216216217; 5: 0.11891891891891893; 10: 0.3081081081081081; 20: 0.6702702702702703}\n",
      "\tF1@: {1:0.016216216216216217; 5: 0.03963963963963965; 10: 0.05601965601965598; 20: 0.0638352638352637}\n",
      "\tNDCG@: {1:0.016216216216216217; 5: 0.09127066016450064; 10: 0.1547779631731765; 20: 0.25015739503272694}\n",
      "\tPrecision@: {1:0.7837837837837838; 5: 0.7167567567567557; 10: 0.7010810810810811; 20: 0.6813513513513513}\n",
      "\tRecall@: {1:0.7837837837837838; 5: 3.5837837837837836; 10: 7.010810810810811; 20: 13.627027027027028}\n",
      "\tF1@: {1:0.7837837837837838; 5: 1.194594594594593; 10: 1.2746928746928747; 20: 1.2978120978120977}\n",
      "\tNDCG@: {1:0.7837837837837838; 5: 2.6457129495351737; 10: 3.8044248657151765; 20: 5.4981787617990046}\n",
      "Epoch  20  training...\n",
      "processed: 20: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:45<00:00, 16.15it/s]\n",
      "epoch loss tensor(803.2512, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:14<00:00, 12.43it/s]\n",
      "\tPrecision@: {1:0.005405405405405406; 5: 0.02486486486486487; 10: 0.03027027027027025; 20: 0.03594594594594586}\n",
      "\tRecall@: {1:0.005405405405405406; 5: 0.12432432432432433; 10: 0.3027027027027027; 20: 0.7189189189189189}\n",
      "\tF1@: {1:0.005405405405405406; 5: 0.041441441441441455; 10: 0.055036855036855; 20: 0.06846846846846832}\n",
      "\tNDCG@: {1:0.005405405405405406; 5: 0.08615654763132817; 10: 0.14744411056748502; 20: 0.2548928906406184}\n",
      "\tPrecision@: {1:0.6810810810810811; 5: 0.7167567567567553; 10: 0.6940540540540541; 20: 0.6789189189189191}\n",
      "\tRecall@: {1:0.6810810810810811; 5: 3.5837837837837836; 10: 6.940540540540541; 20: 13.578378378378378}\n",
      "\tF1@: {1:0.6810810810810811; 5: 1.1945945945945926; 10: 1.261916461916462; 20: 1.2931788931788935}\n",
      "\tNDCG@: {1:0.6810810810810811; 5: 2.5797649283129727; 10: 3.715418238284705; 20: 5.410494853943463}\n",
      "Epoch  21  training...\n",
      "processed: 21: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:46<00:00, 16.05it/s]\n",
      "epoch loss tensor(805.9203, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:14<00:00, 12.39it/s]\n",
      "\tPrecision@: {1:0.010810810810810811; 5: 0.022702702702702707; 10: 0.03027027027027025; 20: 0.03378378378378371}\n",
      "\tRecall@: {1:0.010810810810810811; 5: 0.11351351351351352; 10: 0.3027027027027027; 20: 0.6756756756756757}\n",
      "\tF1@: {1:0.010810810810810811; 5: 0.03783783783783785; 10: 0.055036855036855; 20: 0.06435006435006421}\n",
      "\tNDCG@: {1:0.010810810810810811; 5: 0.07879788213864285; 10: 0.1423670378553008; 20: 0.23995690553739013}\n",
      "\tPrecision@: {1:0.8054054054054054; 5: 0.7459459459459448; 10: 0.7108108108108108; 20: 0.7032432432432432}\n",
      "\tRecall@: {1:0.8054054054054054; 5: 3.72972972972973; 10: 7.108108108108108; 20: 14.064864864864864}\n",
      "\tF1@: {1:0.8054054054054054; 5: 1.2432432432432414; 10: 1.2923832923832923; 20: 1.3395109395109395}\n",
      "\tNDCG@: {1:0.8054054054054054; 5: 2.7099627191422737; 10: 3.851843993757651; 20: 5.630787278153366}\n",
      "Epoch  22  training...\n",
      "processed: 22: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:47<00:00, 15.51it/s]\n",
      "epoch loss tensor(795.6276, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:14<00:00, 12.34it/s]\n",
      "\tPrecision@: {1:0.02702702702702703; 5: 0.0291891891891892; 10: 0.032432432432432406; 20: 0.035135135135135054}\n",
      "\tRecall@: {1:0.02702702702702703; 5: 0.14594594594594595; 10: 0.32432432432432434; 20: 0.7027027027027027}\n",
      "\tF1@: {1:0.02702702702702703; 5: 0.04864864864864866; 10: 0.05896805896805892; 20: 0.06692406692406677}\n",
      "\tNDCG@: {1:0.02702702702702703; 5: 0.09372000932595416; 10: 0.1551030556159802; 20: 0.2528984745529937}\n",
      "\tPrecision@: {1:0.6594594594594595; 5: 0.7113513513513504; 10: 0.7140540540540539; 20: 0.699189189189189}\n",
      "\tRecall@: {1:0.6594594594594595; 5: 3.556756756756757; 10: 7.140540540540541; 20: 13.983783783783784}\n",
      "\tF1@: {1:0.6594594594594595; 5: 1.1855855855855844; 10: 1.298280098280098; 20: 1.3317889317889315}\n",
      "\tNDCG@: {1:0.6594594594594595; 5: 2.5284204200831883; 10: 3.7435915196621434; 20: 5.496080342614075}\n",
      "Epoch  23  training...\n",
      "processed: 23: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:46<00:00, 15.77it/s]\n",
      "epoch loss tensor(800.4211, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 12.33it/s]\n",
      "\tPrecision@: {1:0.02702702702702703; 5: 0.021621621621621626; 10: 0.035135135135135095; 20: 0.03540540540540532}\n",
      "\tRecall@: {1:0.02702702702702703; 5: 0.10810810810810811; 10: 0.35135135135135137; 20: 0.7081081081081081}\n",
      "\tF1@: {1:0.02702702702702703; 5: 0.03603603603603604; 10: 0.06388206388206381; 20: 0.06743886743886729}\n",
      "\tNDCG@: {1:0.02702702702702703; 5: 0.08137237395331402; 10: 0.1639218054045793; 20: 0.25682710732874786}\n",
      "\tPrecision@: {1:0.6918918918918919; 5: 0.7091891891891884; 10: 0.6956756756756753; 20: 0.6894594594594594}\n",
      "\tRecall@: {1:0.6918918918918919; 5: 3.545945945945946; 10: 6.956756756756757; 20: 13.78918918918919}\n",
      "\tF1@: {1:0.6918918918918919; 5: 1.1819819819819808; 10: 1.2648648648648642; 20: 1.3132561132561131}\n",
      "\tNDCG@: {1:0.6918918918918919; 5: 2.572812786989354; 10: 3.7273096463016637; 20: 5.475441849177793}\n",
      "Epoch  24  training...\n",
      "processed: 24: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:47<00:00, 15.67it/s]\n",
      "epoch loss tensor(791.8243, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.84it/s]\n",
      "\tPrecision@: {1:0.021621621621621623; 5: 0.025945945945945955; 10: 0.02972972972972971; 20: 0.034324324324324244}\n",
      "\tRecall@: {1:0.021621621621621623; 5: 0.12972972972972974; 10: 0.2972972972972973; 20: 0.6864864864864865}\n",
      "\tF1@: {1:0.021621621621621623; 5: 0.04324324324324326; 10: 0.054054054054054015; 20: 0.06537966537966523}\n",
      "\tNDCG@: {1:0.021621621621621623; 5: 0.09176674923867424; 10: 0.14774328134430223; 20: 0.25028786342294246}\n",
      "\tPrecision@: {1:0.6810810810810811; 5: 0.7297297297297289; 10: 0.7064864864864867; 20: 0.6881081081081083}\n",
      "\tRecall@: {1:0.6810810810810811; 5: 3.6486486486486487; 10: 7.064864864864865; 20: 13.762162162162163}\n",
      "\tF1@: {1:0.6810810810810811; 5: 1.2162162162162151; 10: 1.2845208845208849; 20: 1.310682110682111}\n",
      "\tNDCG@: {1:0.6810810810810811; 5: 2.59406582377289; 10: 3.7523044748311363; 20: 5.465088762268943}\n",
      "Epoch  25  training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 25: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:46<00:00, 15.97it/s]\n",
      "epoch loss tensor(795.2114, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.74it/s]\n",
      "\tPrecision@: {1:0.03783783783783784; 5: 0.0291891891891892; 10: 0.036756756756756714; 20: 0.03540540540540532}\n",
      "\tRecall@: {1:0.03783783783783784; 5: 0.14594594594594595; 10: 0.3675675675675676; 20: 0.7081081081081081}\n",
      "\tF1@: {1:0.03783783783783784; 5: 0.04864864864864866; 10: 0.06683046683046676; 20: 0.06743886743886729}\n",
      "\tNDCG@: {1:0.03783783783783784; 5: 0.11214283917069949; 10: 0.18530051724581437; 20: 0.2742583361835169}\n",
      "\tPrecision@: {1:0.7189189189189189; 5: 0.7254054054054041; 10: 0.7216216216216211; 20: 0.6975675675675681}\n",
      "\tRecall@: {1:0.7189189189189189; 5: 3.627027027027027; 10: 7.216216216216216; 20: 13.95135135135135}\n",
      "\tF1@: {1:0.7189189189189189; 5: 1.209009009009007; 10: 1.3120393120393112; 20: 1.3287001287001297}\n",
      "\tNDCG@: {1:0.7189189189189189; 5: 2.595273416131504; 10: 3.812500414120847; 20: 5.538192731374773}\n",
      "Epoch  26  training...\n",
      "processed: 26: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:46<00:00, 15.95it/s]\n",
      "epoch loss tensor(795.0417, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.84it/s]\n",
      "\tPrecision@: {1:0.016216216216216217; 5: 0.021621621621621626; 10: 0.032432432432432406; 20: 0.03459459459459451}\n",
      "\tRecall@: {1:0.016216216216216217; 5: 0.10810810810810811; 10: 0.32432432432432434; 20: 0.6918918918918919}\n",
      "\tF1@: {1:0.016216216216216217; 5: 0.03603603603603604; 10: 0.05896805896805892; 20: 0.06589446589446575}\n",
      "\tNDCG@: {1:0.016216216216216217; 5: 0.07393028002515024; 10: 0.1483388758341451; 20: 0.24492551472795798}\n",
      "\tPrecision@: {1:0.745945945945946; 5: 0.7286486486486475; 10: 0.7097297297297298; 20: 0.6956756756756759}\n",
      "\tRecall@: {1:0.745945945945946; 5: 3.6432432432432433; 10: 7.097297297297297; 20: 13.913513513513514}\n",
      "\tF1@: {1:0.745945945945946; 5: 1.214414414414413; 10: 1.2904176904176905; 20: 1.3250965250965256}\n",
      "\tNDCG@: {1:0.745945945945946; 5: 2.6631846087973687; 10: 3.831172197750879; 20: 5.572960488810059}\n",
      "Epoch  27  training...\n",
      "processed: 27: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:46<00:00, 15.81it/s]\n",
      "epoch loss tensor(790.8455, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.89it/s]\n",
      "\tPrecision@: {1:0.010810810810810811; 5: 0.016216216216216217; 10: 0.028648648648648634; 20: 0.03378378378378371}\n",
      "\tRecall@: {1:0.010810810810810811; 5: 0.08108108108108109; 10: 0.2864864864864865; 20: 0.6756756756756757}\n",
      "\tF1@: {1:0.010810810810810811; 5: 0.02702702702702703; 10: 0.05208845208845207; 20: 0.06435006435006421}\n",
      "\tNDCG@: {1:0.010810810810810811; 5: 0.05467835401625917; 10: 0.12228825007083825; 20: 0.22368166990678834}\n",
      "\tPrecision@: {1:0.6270270270270271; 5: 0.7189189189189183; 10: 0.7091891891891892; 20: 0.7056756756756756}\n",
      "\tRecall@: {1:0.6270270270270271; 5: 3.5945945945945947; 10: 7.091891891891892; 20: 14.113513513513514}\n",
      "\tF1@: {1:0.6270270270270271; 5: 1.1981981981981973; 10: 1.2894348894348893; 20: 1.344144144144144}\n",
      "\tNDCG@: {1:0.6270270270270271; 5: 2.568118178216445; 10: 3.75123184398102; 20: 5.549570485832679}\n",
      "Epoch  28  training...\n",
      "processed: 28: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:46<00:00, 16.00it/s]\n",
      "epoch loss tensor(784.9177, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:16<00:00, 11.25it/s]\n",
      "\tPrecision@: {1:0.021621621621621623; 5: 0.02378378378378379; 10: 0.03027027027027025; 20: 0.03540540540540532}\n",
      "\tRecall@: {1:0.021621621621621623; 5: 0.11891891891891893; 10: 0.3027027027027027; 20: 0.7081081081081081}\n",
      "\tF1@: {1:0.021621621621621623; 5: 0.03963963963963965; 10: 0.055036855036855; 20: 0.06743886743886729}\n",
      "\tNDCG@: {1:0.021621621621621623; 5: 0.08041813513595061; 10: 0.14314978436784806; 20: 0.24960260436259352}\n",
      "\tPrecision@: {1:0.6486486486486487; 5: 0.6843243243243232; 10: 0.6810810810810809; 20: 0.6775675675675673}\n",
      "\tRecall@: {1:0.6486486486486487; 5: 3.4216216216216218; 10: 6.8108108108108105; 20: 13.551351351351352}\n",
      "\tF1@: {1:0.6486486486486487; 5: 1.140540540540539; 10: 1.2383292383292381; 20: 1.2906048906048901}\n",
      "\tNDCG@: {1:0.6486486486486487; 5: 2.420538293030054; 10: 3.568896915599589; 20: 5.291944430057504}\n",
      "Epoch  29  training...\n",
      "processed: 29: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:46<00:00, 16.08it/s]\n",
      "epoch loss tensor(771.0155, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.72it/s]\n",
      "\tPrecision@: {1:0.005405405405405406; 5: 0.02810810810810812; 10: 0.03135135135135133; 20: 0.0329729729729729}\n",
      "\tRecall@: {1:0.005405405405405406; 5: 0.14054054054054055; 10: 0.31351351351351353; 20: 0.6594594594594595}\n",
      "\tF1@: {1:0.005405405405405406; 5: 0.04684684684684686; 10: 0.05700245700245697; 20: 0.06280566280566267}\n",
      "\tNDCG@: {1:0.005405405405405406; 5: 0.08557018700010682; 10: 0.1425816432106927; 20: 0.23285883450280268}\n",
      "\tPrecision@: {1:0.6486486486486487; 5: 0.6994594594594584; 10: 0.6956756756756755; 20: 0.6878378378378378}\n",
      "\tRecall@: {1:0.6486486486486487; 5: 3.497297297297297; 10: 6.956756756756757; 20: 13.756756756756756}\n",
      "\tF1@: {1:0.6486486486486487; 5: 1.1657657657657643; 10: 1.2648648648648644; 20: 1.3101673101673101}\n",
      "\tNDCG@: {1:0.6486486486486487; 5: 2.504256109508253; 10: 3.676117750805748; 20: 5.417030354195678}\n",
      "Epoch  30  training...\n",
      "processed: 30: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:46<00:00, 15.85it/s]\n",
      "epoch loss tensor(772.0540, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 12.29it/s]\n",
      "\tPrecision@: {1:0.005405405405405406; 5: 0.02810810810810812; 10: 0.03135135135135133; 20: 0.03459459459459451}\n",
      "\tRecall@: {1:0.005405405405405406; 5: 0.14054054054054055; 10: 0.31351351351351353; 20: 0.6918918918918919}\n",
      "\tF1@: {1:0.005405405405405406; 5: 0.04684684684684686; 10: 0.05700245700245697; 20: 0.06589446589446575}\n",
      "\tNDCG@: {1:0.005405405405405406; 5: 0.09426465573943629; 10: 0.15206108521272693; 20: 0.25156891947968724}\n",
      "\tPrecision@: {1:0.6486486486486487; 5: 0.6735135135135126; 10: 0.6735135135135133; 20: 0.67972972972973}\n",
      "\tRecall@: {1:0.6486486486486487; 5: 3.3675675675675674; 10: 6.735135135135135; 20: 13.594594594594595}\n",
      "\tF1@: {1:0.6486486486486487; 5: 1.1225225225225213; 10: 1.2245700245700242; 20: 1.2947232947232952}\n",
      "\tNDCG@: {1:0.6486486486486487; 5: 2.429829740408929; 10: 3.5726739196577393; 20: 5.326224849712084}\n",
      "Epoch  31  training...\n",
      "processed: 31: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:47<00:00, 15.70it/s]\n",
      "epoch loss tensor(771.6099, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 12.19it/s]\n",
      "\tPrecision@: {1:0.010810810810810811; 5: 0.022702702702702707; 10: 0.031891891891891865; 20: 0.03324324324324317}\n",
      "\tRecall@: {1:0.010810810810810811; 5: 0.11351351351351352; 10: 0.31891891891891894; 20: 0.6648648648648648}\n",
      "\tF1@: {1:0.010810810810810811; 5: 0.03783783783783785; 10: 0.05798525798525793; 20: 0.06332046332046318}\n",
      "\tNDCG@: {1:0.010810810810810811; 5: 0.07484280462477445; 10: 0.14430297492281582; 20: 0.23561761818109525}\n",
      "\tPrecision@: {1:0.6918918918918919; 5: 0.6864864864864858; 10: 0.6816216216216214; 20: 0.6805405405405407}\n",
      "\tRecall@: {1:0.6918918918918919; 5: 3.4324324324324325; 10: 6.816216216216216; 20: 13.610810810810811}\n",
      "\tF1@: {1:0.6918918918918919; 5: 1.1441441441441433; 10: 1.2393120393120391; 20: 1.2962676962676967}\n",
      "\tNDCG@: {1:0.6918918918918919; 5: 2.484913911942315; 10: 3.63216929458625; 20: 5.371799624651624}\n",
      "Epoch  32  training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 32: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:47<00:00, 15.73it/s]\n",
      "epoch loss tensor(766.0787, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.85it/s]\n",
      "\tPrecision@: {1:0.02702702702702703; 5: 0.02486486486486487; 10: 0.03459459459459456; 20: 0.035135135135135054}\n",
      "\tRecall@: {1:0.02702702702702703; 5: 0.12432432432432433; 10: 0.34594594594594597; 20: 0.7027027027027027}\n",
      "\tF1@: {1:0.02702702702702703; 5: 0.041441441441441455; 10: 0.06289926289926284; 20: 0.06692406692406677}\n",
      "\tNDCG@: {1:0.02702702702702703; 5: 0.0839916482205383; 10: 0.159976927313376; 20: 0.2539291727923173}\n",
      "\tPrecision@: {1:0.7513513513513513; 5: 0.7113513513513504; 10: 0.6935135135135131; 20: 0.6932432432432434}\n",
      "\tRecall@: {1:0.7513513513513513; 5: 3.556756756756757; 10: 6.935135135135135; 20: 13.864864864864865}\n",
      "\tF1@: {1:0.7513513513513513; 5: 1.1855855855855844; 10: 1.2609336609336603; 20: 1.3204633204633207}\n",
      "\tNDCG@: {1:0.7513513513513513; 5: 2.590139480885565; 10: 3.7317965716857007; 20: 5.502362314060431}\n",
      "Epoch  33  training...\n",
      "processed: 33: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:47<00:00, 15.63it/s]\n",
      "epoch loss tensor(764.9828, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.61it/s]\n",
      "\tPrecision@: {1:0.021621621621621623; 5: 0.021621621621621626; 10: 0.03135135135135133; 20: 0.03378378378378371}\n",
      "\tRecall@: {1:0.021621621621621623; 5: 0.10810810810810811; 10: 0.31351351351351353; 20: 0.6756756756756757}\n",
      "\tF1@: {1:0.021621621621621623; 5: 0.03603603603603604; 10: 0.05700245700245697; 20: 0.06435006435006421}\n",
      "\tNDCG@: {1:0.021621621621621623; 5: 0.06939568500162983; 10: 0.13853904034361766; 20: 0.2329357916120137}\n",
      "\tPrecision@: {1:0.7513513513513513; 5: 0.7178378378378367; 10: 0.6967567567567566; 20: 0.6854054054054053}\n",
      "\tRecall@: {1:0.7513513513513513; 5: 3.5891891891891894; 10: 6.967567567567568; 20: 13.708108108108108}\n",
      "\tF1@: {1:0.7513513513513513; 5: 1.1963963963963948; 10: 1.2668304668304669; 20: 1.3055341055341052}\n",
      "\tNDCG@: {1:0.7513513513513513; 5: 2.6173046301570078; 10: 3.7577753319092815; 20: 5.480784178685594}\n",
      "Epoch  34  training...\n",
      "processed: 34: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:47<00:00, 15.57it/s]\n",
      "epoch loss tensor(766.4674, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 12.13it/s]\n",
      "\tPrecision@: {1:0.016216216216216217; 5: 0.01837837837837838; 10: 0.032432432432432406; 20: 0.03378378378378371}\n",
      "\tRecall@: {1:0.016216216216216217; 5: 0.0918918918918919; 10: 0.32432432432432434; 20: 0.6756756756756757}\n",
      "\tF1@: {1:0.016216216216216217; 5: 0.030630630630630637; 10: 0.05896805896805892; 20: 0.06435006435006421}\n",
      "\tNDCG@: {1:0.016216216216216217; 5: 0.05954595612975176; 10: 0.138927996269323; 20: 0.23036299108817357}\n",
      "\tPrecision@: {1:0.7135135135135136; 5: 0.7189189189189183; 10: 0.7048648648648648; 20: 0.6981081081081084}\n",
      "\tRecall@: {1:0.7135135135135136; 5: 3.5945945945945947; 10: 7.048648648648649; 20: 13.962162162162162}\n",
      "\tF1@: {1:0.7135135135135136; 5: 1.1981981981981973; 10: 1.2815724815724814; 20: 1.3297297297297304}\n",
      "\tNDCG@: {1:0.7135135135135136; 5: 2.6090372149514525; 10: 3.7770840961271133; 20: 5.547033434839771}\n",
      "Epoch  35  training...\n",
      "processed: 35: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:46<00:00, 15.95it/s]\n",
      "epoch loss tensor(751.4642, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 12.12it/s]\n",
      "\tPrecision@: {1:0.010810810810810811; 5: 0.02486486486486487; 10: 0.03405405405405402; 20: 0.03378378378378371}\n",
      "\tRecall@: {1:0.010810810810810811; 5: 0.12432432432432433; 10: 0.34054054054054056; 20: 0.6756756756756757}\n",
      "\tF1@: {1:0.010810810810810811; 5: 0.041441441441441455; 10: 0.06191646191646186; 20: 0.06435006435006421}\n",
      "\tNDCG@: {1:0.010810810810810811; 5: 0.08058121712015204; 10: 0.15136274960340507; 20: 0.23905734571161613}\n",
      "\tPrecision@: {1:0.6918918918918919; 5: 0.7005405405405392; 10: 0.6729729729729729; 20: 0.6810810810810817}\n",
      "\tRecall@: {1:0.6918918918918919; 5: 3.502702702702703; 10: 6.72972972972973; 20: 13.621621621621621}\n",
      "\tF1@: {1:0.6918918918918919; 5: 1.1675675675675656; 10: 1.2235872235872234; 20: 1.2972972972972983}\n",
      "\tNDCG@: {1:0.6918918918918919; 5: 2.5067403297658784; 10: 3.603118193137203; 20: 5.367652025181843}\n",
      "Epoch  36  training...\n",
      "processed: 36: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:45<00:00, 16.10it/s]\n",
      "epoch loss tensor(757.6188, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.81it/s]\n",
      "\tPrecision@: {1:0.016216216216216217; 5: 0.020540540540540546; 10: 0.03621621621621617; 20: 0.03594594594594586}\n",
      "\tRecall@: {1:0.016216216216216217; 5: 0.10270270270270271; 10: 0.3621621621621622; 20: 0.7189189189189189}\n",
      "\tF1@: {1:0.016216216216216217; 5: 0.034234234234234245; 10: 0.06584766584766578; 20: 0.06846846846846832}\n",
      "\tNDCG@: {1:0.016216216216216217; 5: 0.07197701993787031; 10: 0.15928862765063387; 20: 0.2527946107496107}\n",
      "\tPrecision@: {1:0.7297297297297297; 5: 0.678918918918918; 10: 0.6718918918918917; 20: 0.6762162162162163}\n",
      "\tRecall@: {1:0.7297297297297297; 5: 3.3945945945945946; 10: 6.718918918918919; 20: 13.524324324324324}\n",
      "\tF1@: {1:0.7297297297297297; 5: 1.1315315315315302; 10: 1.2216216216216211; 20: 1.2880308880308882}\n",
      "\tNDCG@: {1:0.7297297297297297; 5: 2.498931064303513; 10: 3.6230151925808016; 20: 5.363913843201185}\n",
      "Epoch  37  training...\n",
      "processed: 37: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:45<00:00, 16.28it/s]\n",
      "epoch loss tensor(761.0392, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 12.02it/s]\n",
      "\tPrecision@: {1:0.032432432432432434; 5: 0.022702702702702707; 10: 0.028108108108108095; 20: 0.03378378378378371}\n",
      "\tRecall@: {1:0.032432432432432434; 5: 0.11351351351351352; 10: 0.2810810810810811; 20: 0.6756756756756757}\n",
      "\tF1@: {1:0.032432432432432434; 5: 0.03783783783783785; 10: 0.05110565110565109; 20: 0.06435006435006421}\n",
      "\tNDCG@: {1:0.032432432432432434; 5: 0.08440808374598889; 10: 0.14117918834612184; 20: 0.24459533636384756}\n",
      "\tPrecision@: {1:0.772972972972973; 5: 0.7005405405405397; 10: 0.6897297297297296; 20: 0.6908108108108107}\n",
      "\tRecall@: {1:0.772972972972973; 5: 3.502702702702703; 10: 6.897297297297297; 20: 13.816216216216215}\n",
      "\tF1@: {1:0.772972972972973; 5: 1.1675675675675663; 10: 1.2540540540540537; 20: 1.3158301158301158}\n",
      "\tNDCG@: {1:0.772972972972973; 5: 2.5458137879369267; 10: 3.6939386171991115; 20: 5.464271482974159}\n",
      "Epoch  38  training...\n",
      "processed: 38: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:46<00:00, 15.90it/s]\n",
      "epoch loss tensor(743.3412, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.93it/s]\n",
      "\tPrecision@: {1:0.032432432432432434; 5: 0.02486486486486487; 10: 0.035135135135135095; 20: 0.035135135135135054}\n",
      "\tRecall@: {1:0.032432432432432434; 5: 0.12432432432432433; 10: 0.35135135135135137; 20: 0.7027027027027027}\n",
      "\tF1@: {1:0.032432432432432434; 5: 0.041441441441441455; 10: 0.06388206388206381; 20: 0.06692406692406677}\n",
      "\tNDCG@: {1:0.032432432432432434; 5: 0.08906404653597152; 10: 0.16193632252408735; 20: 0.2539417408162013}\n",
      "\tPrecision@: {1:0.772972972972973; 5: 0.6908108108108098; 10: 0.6729729729729732; 20: 0.6810810810810811}\n",
      "\tRecall@: {1:0.772972972972973; 5: 3.454054054054054; 10: 6.72972972972973; 20: 13.621621621621621}\n",
      "\tF1@: {1:0.772972972972973; 5: 1.1513513513513498; 10: 1.223587223587224; 20: 1.2972972972972974}\n",
      "\tNDCG@: {1:0.772972972972973; 5: 2.5188701893453787; 10: 3.6316047822427278; 20: 5.39224102391045}\n",
      "Epoch  39  training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 39: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:45<00:00, 16.27it/s]\n",
      "epoch loss tensor(744.1295, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.87it/s]\n",
      "\tPrecision@: {1:0.016216216216216217; 5: 0.021621621621621626; 10: 0.03297297297297294; 20: 0.03540540540540532}\n",
      "\tRecall@: {1:0.016216216216216217; 5: 0.10810810810810811; 10: 0.32972972972972975; 20: 0.7081081081081081}\n",
      "\tF1@: {1:0.016216216216216217; 5: 0.03603603603603604; 10: 0.0599508599508599; 20: 0.06743886743886729}\n",
      "\tNDCG@: {1:0.016216216216216217; 5: 0.07122757732244754; 10: 0.14428849485082632; 20: 0.2423313070206656}\n",
      "\tPrecision@: {1:0.7567567567567568; 5: 0.682162162162161; 10: 0.682162162162162; 20: 0.6827027027027028}\n",
      "\tRecall@: {1:0.7567567567567568; 5: 3.4108108108108106; 10: 6.821621621621621; 20: 13.654054054054054}\n",
      "\tF1@: {1:0.7567567567567568; 5: 1.1369369369369353; 10: 1.24029484029484; 20: 1.3003861003861006}\n",
      "\tNDCG@: {1:0.7567567567567568; 5: 2.4828710869499298; 10: 3.6389903083587543; 20: 5.383161626943546}\n",
      "Epoch  40  training...\n",
      "processed: 40: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:45<00:00, 16.37it/s]\n",
      "epoch loss tensor(728.5803, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.94it/s]\n",
      "\tPrecision@: {1:0.016216216216216217; 5: 0.0172972972972973; 10: 0.03135135135135133; 20: 0.034864864864864786}\n",
      "\tRecall@: {1:0.016216216216216217; 5: 0.08648648648648649; 10: 0.31351351351351353; 20: 0.6972972972972973}\n",
      "\tF1@: {1:0.016216216216216217; 5: 0.028828828828828836; 10: 0.05700245700245697; 20: 0.06640926640926627}\n",
      "\tNDCG@: {1:0.016216216216216217; 5: 0.060083759421664565; 10: 0.13670615945495226; 20: 0.23704275890918525}\n",
      "\tPrecision@: {1:0.6864864864864865; 5: 0.6810810810810801; 10: 0.6794594594594595; 20: 0.6824324324324322}\n",
      "\tRecall@: {1:0.6864864864864865; 5: 3.4054054054054053; 10: 6.794594594594595; 20: 13.64864864864865}\n",
      "\tF1@: {1:0.6864864864864865; 5: 1.1351351351351338; 10: 1.2353808353808353; 20: 1.2998712998712996}\n",
      "\tNDCG@: {1:0.6864864864864865; 5: 2.4448315211449625; 10: 3.5946736727533035; 20: 5.347543677384878}\n",
      "Epoch  41  training...\n",
      "processed: 41: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:45<00:00, 16.40it/s]\n",
      "epoch loss tensor(727.2888, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 12.02it/s]\n",
      "\tPrecision@: {1:0.016216216216216217; 5: 0.0172972972972973; 10: 0.029189189189189172; 20: 0.03378378378378371}\n",
      "\tRecall@: {1:0.016216216216216217; 5: 0.08648648648648649; 10: 0.2918918918918919; 20: 0.6756756756756757}\n",
      "\tF1@: {1:0.016216216216216217; 5: 0.028828828828828836; 10: 0.053071253071253044; 20: 0.06435006435006421}\n",
      "\tNDCG@: {1:0.016216216216216217; 5: 0.056298607013566926; 10: 0.12725476217432782; 20: 0.22855010555621216}\n",
      "\tPrecision@: {1:0.745945945945946; 5: 0.6951351351351344; 10: 0.6783783783783784; 20: 0.6827027027027027}\n",
      "\tRecall@: {1:0.745945945945946; 5: 3.4756756756756757; 10: 6.783783783783784; 20: 13.654054054054054}\n",
      "\tF1@: {1:0.745945945945946; 5: 1.1585585585585576; 10: 1.2334152334152335; 20: 1.3003861003861004}\n",
      "\tNDCG@: {1:0.745945945945946; 5: 2.517259847704452; 10: 3.6371723171867663; 20: 5.394842278016836}\n",
      "Epoch  42  training...\n",
      "processed: 42: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:45<00:00, 16.27it/s]\n",
      "epoch loss tensor(714.5817, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 11.98it/s]\n",
      "\tPrecision@: {1:0.010810810810810811; 5: 0.015135135135135137; 10: 0.028108108108108095; 20: 0.034864864864864786}\n",
      "\tRecall@: {1:0.010810810810810811; 5: 0.07567567567567568; 10: 0.2810810810810811; 20: 0.6972972972972973}\n",
      "\tF1@: {1:0.010810810810810811; 5: 0.025225225225225228; 10: 0.05110565110565109; 20: 0.06640926640926627}\n",
      "\tNDCG@: {1:0.010810810810810811; 5: 0.059417745241720235; 10: 0.12742312123322813; 20: 0.23744264210026794}\n",
      "\tPrecision@: {1:0.7837837837837838; 5: 0.7210810810810804; 10: 0.702162162162162; 20: 0.6927027027027026}\n",
      "\tRecall@: {1:0.7837837837837838; 5: 3.6054054054054054; 10: 7.021621621621621; 20: 13.854054054054053}\n",
      "\tF1@: {1:0.7837837837837838; 5: 1.2018018018018009; 10: 1.2766584766584763; 20: 1.3194337194337191}\n",
      "\tNDCG@: {1:0.7837837837837838; 5: 2.6018347883214004; 10: 3.758995978681254; 20: 5.506765238670128}\n",
      "Epoch  43  training...\n",
      "processed: 43: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:46<00:00, 15.78it/s]\n",
      "epoch loss tensor(706.3682, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 12.19it/s]\n",
      "\tPrecision@: {1:0.005405405405405406; 5: 0.02486486486486487; 10: 0.03297297297297294; 20: 0.03540540540540532}\n",
      "\tRecall@: {1:0.005405405405405406; 5: 0.12432432432432433; 10: 0.32972972972972975; 20: 0.7081081081081081}\n",
      "\tF1@: {1:0.005405405405405406; 5: 0.041441441441441455; 10: 0.0599508599508599; 20: 0.06743886743886729}\n",
      "\tNDCG@: {1:0.005405405405405406; 5: 0.08382856623633686; 10: 0.15039614058943268; 20: 0.2489279692057628}\n",
      "\tPrecision@: {1:0.7837837837837838; 5: 0.7135135135135126; 10: 0.691891891891892; 20: 0.6927027027027028}\n",
      "\tRecall@: {1:0.7837837837837838; 5: 3.5675675675675675; 10: 6.918918918918919; 20: 13.854054054054053}\n",
      "\tF1@: {1:0.7837837837837838; 5: 1.189189189189188; 10: 1.2579852579852582; 20: 1.3194337194337196}\n",
      "\tNDCG@: {1:0.7837837837837838; 5: 2.6042909806044237; 10: 3.740465519410756; 20: 5.515105132708564}\n",
      "Epoch  44  training...\n",
      "processed: 44: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:46<00:00, 15.97it/s]\n",
      "epoch loss tensor(705.8246, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 12.33it/s]\n",
      "\tPrecision@: {1:0.010810810810810811; 5: 0.016216216216216217; 10: 0.03027027027027025; 20: 0.03324324324324317}\n",
      "\tRecall@: {1:0.010810810810810811; 5: 0.08108108108108109; 10: 0.3027027027027027; 20: 0.6648648648648648}\n",
      "\tF1@: {1:0.010810810810810811; 5: 0.02702702702702703; 10: 0.055036855036855; 20: 0.06332046332046318}\n",
      "\tNDCG@: {1:0.010810810810810811; 5: 0.054303632708547774; 10: 0.12784248207050547; 20: 0.22249988198870724}\n",
      "\tPrecision@: {1:0.7243243243243244; 5: 0.6918918918918909; 10: 0.6870270270270271; 20: 0.6881081081081081}\n",
      "\tRecall@: {1:0.7243243243243244; 5: 3.4594594594594597; 10: 6.870270270270271; 20: 13.762162162162163}\n",
      "\tF1@: {1:0.7243243243243244; 5: 1.1531531531531518; 10: 1.2491400491400493; 20: 1.3106821106821105}\n",
      "\tNDCG@: {1:0.7243243243243244; 5: 2.5363107523981596; 10: 3.6917781853658904; 20: 5.454088733755864}\n",
      "Epoch  45  training...\n",
      "processed: 45: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:46<00:00, 15.95it/s]\n",
      "epoch loss tensor(700.3240, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:14<00:00, 12.50it/s]\n",
      "\tPrecision@: {1:0.010810810810810811; 5: 0.01837837837837838; 10: 0.03297297297297294; 20: 0.034864864864864786}\n",
      "\tRecall@: {1:0.010810810810810811; 5: 0.0918918918918919; 10: 0.32972972972972975; 20: 0.6972972972972973}\n",
      "\tF1@: {1:0.010810810810810811; 5: 0.030630630630630637; 10: 0.0599508599508599; 20: 0.06640926640926627}\n",
      "\tNDCG@: {1:0.010810810810810811; 5: 0.06403199381396366; 10: 0.14220320387810165; 20: 0.237100012696213}\n",
      "\tPrecision@: {1:0.745945945945946; 5: 0.7091891891891879; 10: 0.6789189189189188; 20: 0.6864864864864867}\n",
      "\tRecall@: {1:0.745945945945946; 5: 3.545945945945946; 10: 6.789189189189189; 20: 13.72972972972973}\n",
      "\tF1@: {1:0.745945945945946; 5: 1.1819819819819801; 10: 1.234398034398034; 20: 1.3075933075933077}\n",
      "\tNDCG@: {1:0.745945945945946; 5: 2.5827110732005414; 10: 3.6784825800814245; 20: 5.452894182974615}\n",
      "Epoch  46  training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 46: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:47<00:00, 15.72it/s]\n",
      "epoch loss tensor(688.7150, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:14<00:00, 12.48it/s]\n",
      "\tPrecision@: {1:0.021621621621621623; 5: 0.016216216216216217; 10: 0.03027027027027025; 20: 0.03405405405405398}\n",
      "\tRecall@: {1:0.021621621621621623; 5: 0.08108108108108109; 10: 0.3027027027027027; 20: 0.6810810810810811}\n",
      "\tF1@: {1:0.021621621621621623; 5: 0.02702702702702703; 10: 0.055036855036855; 20: 0.06486486486486473}\n",
      "\tNDCG@: {1:0.021621621621621623; 5: 0.05813049933438464; 10: 0.132316184360796; 20: 0.23091820953744455}\n",
      "\tPrecision@: {1:0.8; 5: 0.7059459459459448; 10: 0.7113513513513512; 20: 0.7054054054054053}\n",
      "\tRecall@: {1:0.8; 5: 3.5297297297297296; 10: 7.113513513513514; 20: 14.108108108108109}\n",
      "\tF1@: {1:0.8; 5: 1.176576576576575; 10: 1.2933660933660933; 20: 1.3436293436293436}\n",
      "\tNDCG@: {1:0.8; 5: 2.5672791706959175; 10: 3.7796837090735655; 20: 5.566489738330695}\n",
      "Epoch  47  training...\n",
      "processed: 47: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:46<00:00, 15.88it/s]\n",
      "epoch loss tensor(677.1066, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:14<00:00, 12.66it/s]\n",
      "\tPrecision@: {1:0.016216216216216217; 5: 0.016216216216216217; 10: 0.029189189189189172; 20: 0.033513513513513435}\n",
      "\tRecall@: {1:0.016216216216216217; 5: 0.08108108108108109; 10: 0.2918918918918919; 20: 0.6702702702702703}\n",
      "\tF1@: {1:0.016216216216216217; 5: 0.02702702702702703; 10: 0.053071253071253044; 20: 0.0638352638352637}\n",
      "\tNDCG@: {1:0.016216216216216217; 5: 0.05480656490429068; 10: 0.12590416219631684; 20: 0.2256179597745622}\n",
      "\tPrecision@: {1:0.7891891891891892; 5: 0.7135135135135124; 10: 0.7043243243243242; 20: 0.6889189189189192}\n",
      "\tRecall@: {1:0.7891891891891892; 5: 3.5675675675675675; 10: 7.043243243243243; 20: 13.778378378378378}\n",
      "\tF1@: {1:0.7891891891891892; 5: 1.1891891891891877; 10: 1.2805896805896804; 20: 1.3122265122265129}\n",
      "\tNDCG@: {1:0.7891891891891892; 5: 2.6116845171932774; 10: 3.7871672070824487; 20: 5.509708487408795}\n",
      "Epoch  48  training...\n",
      "processed: 48: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:47<00:00, 15.47it/s]\n",
      "epoch loss tensor(686.3989, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:14<00:00, 12.40it/s]\n",
      "\tPrecision@: {1:0.016216216216216217; 5: 0.021621621621621626; 10: 0.03027027027027025; 20: 0.03324324324324317}\n",
      "\tRecall@: {1:0.016216216216216217; 5: 0.10810810810810811; 10: 0.3027027027027027; 20: 0.6648648648648648}\n",
      "\tF1@: {1:0.016216216216216217; 5: 0.03603603603603604; 10: 0.055036855036855; 20: 0.06332046332046318}\n",
      "\tNDCG@: {1:0.016216216216216217; 5: 0.06760550689855134; 10: 0.13338026639287315; 20: 0.22829299354213692}\n",
      "\tPrecision@: {1:0.7891891891891892; 5: 0.6918918918918907; 10: 0.6875675675675678; 20: 0.6843243243243243}\n",
      "\tRecall@: {1:0.7891891891891892; 5: 3.4594594594594597; 10: 6.875675675675676; 20: 13.686486486486487}\n",
      "\tF1@: {1:0.7891891891891892; 5: 1.1531531531531516; 10: 1.2501228501228505; 20: 1.3034749034749034}\n",
      "\tNDCG@: {1:0.7891891891891892; 5: 2.5287472907035355; 10: 3.6864075332499673; 20: 5.429665792857187}\n",
      "Epoch  49  training...\n",
      "processed: 49: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:47<00:00, 15.54it/s]\n",
      "epoch loss tensor(672.5155, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:14<00:00, 12.46it/s]\n",
      "\tPrecision@: {1:0.016216216216216217; 5: 0.020540540540540546; 10: 0.035135135135135095; 20: 0.03594594594594586}\n",
      "\tRecall@: {1:0.016216216216216217; 5: 0.10270270270270271; 10: 0.35135135135135137; 20: 0.7189189189189189}\n",
      "\tF1@: {1:0.016216216216216217; 5: 0.034234234234234245; 10: 0.06388206388206381; 20: 0.06846846846846832}\n",
      "\tNDCG@: {1:0.016216216216216217; 5: 0.06365727250625226; 10: 0.14575803606054152; 20: 0.2417443077463992}\n",
      "\tPrecision@: {1:0.7513513513513513; 5: 0.6994594594594588; 10: 0.694054054054054; 20: 0.6943243243243241}\n",
      "\tRecall@: {1:0.7513513513513513; 5: 3.497297297297297; 10: 6.940540540540541; 20: 13.886486486486486}\n",
      "\tF1@: {1:0.7513513513513513; 5: 1.1657657657657647; 10: 1.2619164619164618; 20: 1.3225225225225221}\n",
      "\tNDCG@: {1:0.7513513513513513; 5: 2.5417609402561188; 10: 3.7043509756605992; 20: 5.477859266544693}\n",
      "Epoch  50  training...\n",
      "processed: 50: 100%|█████████████████████████████████████████████████████████████████| 740/740 [00:47<00:00, 15.51it/s]\n",
      "epoch loss tensor(658.0331, grad_fn=<AddBackward0>)\n",
      "starting val...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 185/185 [00:15<00:00, 12.33it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-9782692c2539>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[0mecoDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mecoScores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposItems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mtestResult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mranking_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoreDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'negNum_test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[0mtestResult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mranking_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mecoDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'negNum_test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;31m#         with open('./results/'+category+'/'+category+'_PT_valResult_'+str(epoch)+'.json', 'w') as outfile:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\\evaluation.py\u001b[0m in \u001b[0;36mranking_performance\u001b[1;34m(score_dict, k)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mavgRecall\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0muserRecall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mavgNDCG\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0muserDCG\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0muserIDCG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mavgAUC\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[1;31m# avgFPR += userFPR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;31m# avgTPR += userTPR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\march\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\march\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     if y_type == \"multiclass\" or (y_type == \"binary\" and\n",
      "\u001b[1;32mc:\\users\\march\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\march\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\march\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "trainset = data_loader.TransactionData(train, userNum, itemNum, distribution)\n",
    "trainLoader = DataLoader(trainset, batch_size=params['batch_size'], shuffle=False, num_workers=0)\n",
    "\n",
    "trainset = data_loader.TransactionData(train, userNum, itemNum, trainset.userHist)\n",
    "trainLoader = DataLoader(trainset, batch_size=params['batch_size'], shuffle=False, num_workers=0)\n",
    "\n",
    "testset = data_loader.UserTransactionData(test, userNum, itemNum, trainset.userHist)\n",
    "testset.set_negN(params['negNum_test'])\n",
    "testLoader = DataLoader(testset, batch_size=params['batch_size'], shuffle=False, num_workers=0)\n",
    "model = PT(userLen=userNum, itemLen=itemNum, distribution=distribution, params=params, item_price=item_price)\n",
    "# print('initialization', model.state_dict())\n",
    "# optimizer = optim.SGD(model.parameters(), lr=params['lr'], weight_decay=params['w_decay'])\n",
    "optimizer = optim.Adam(model.parameters(), lr=params['lr'], weight_decay=params['w_decay'])\n",
    "\n",
    "epoch = 0\n",
    "print('start training...')\n",
    "while epoch < params['epoch_limit']:\n",
    "    model.device = params['train_device']\n",
    "    model.to(model.device)\n",
    "\n",
    "    epoch += 1\n",
    "    print('Epoch ', str(epoch), ' training...')\n",
    "    L = len(trainLoader.dataset)\n",
    "    pbar = tqdm(total = L, file=sys.stdout)\n",
    "    pbar.set_description('processed: %d' % epoch)\n",
    "    for i, batchData in enumerate(trainLoader):\n",
    "        optimizer.zero_grad()\n",
    "        users = torch.LongTensor(batchData['user']).to(model.device)\n",
    "        items = torch.LongTensor(batchData['item']).to(model.device)\n",
    "        negItems = torch.LongTensor(batchData['negItem']).reshape(-1).to(model.device)\n",
    "        batch_loss = model.loss(users, items, negItems)\n",
    "        batch_loss.backward()\n",
    "        grads = model.get_grads()\n",
    "        \n",
    "#         print('userBias_g:',grads['userBias_g'])\n",
    "#         print('itemBias_g:',grads['itemBias_g'])\n",
    "#         print('userEmbed_g:',grads['userEmbed_g'])\n",
    "#         print('itemEmbed_g:',grads['itemEmbed_g'])\n",
    "#         input()\n",
    "\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if i == 0:\n",
    "            total_loss = batch_loss.clone()\n",
    "        else:\n",
    "            total_loss += batch_loss.clone()\n",
    "        pbar.update(users.shape[0])\n",
    "    pbar.close()\n",
    "    print('epoch loss', total_loss)\n",
    "#     print(model.state_dict())\n",
    "\n",
    "    if epoch % params['test_per_train'] == 0:\n",
    "        print('starting val...')\n",
    "        model.device = params['test_device']\n",
    "        model.to(model.device)\n",
    "        L = len(testLoader.dataset)\n",
    "        pbar = tqdm(total=L, file=sys.stdout)\n",
    "        with torch.no_grad():\n",
    "            scoreDict = dict()\n",
    "            ecoDict = dict()\n",
    "            for i, batchData in enumerate(testLoader):\n",
    "#                 if np.random.random() < 0.98:\n",
    "#                     pbar.update(1)\n",
    "#                     continue\n",
    "#                 if i%50 != 0:\n",
    "#                     pbar.update(1)\n",
    "#                     continue\n",
    "                user = torch.LongTensor(batchData['user']).to(model.device)\n",
    "                posItems = torch.LongTensor(batchData['posItem']).to(model.device)\n",
    "                negItems = torch.LongTensor(batchData['negItem']).to(model.device)\n",
    "\n",
    "                items = torch.cat((posItems, negItems), 1).view(-1)\n",
    "                users = user.expand(items.shape[0])\n",
    "\n",
    "                score = model.forward(users, items)\n",
    "                scoreHeap = list()\n",
    "                ecoHeap = list()\n",
    "                for j in range(score.shape[0]):\n",
    "                    gt = False\n",
    "                    et = False\n",
    "                    if j < posItems.shape[1]:\n",
    "                        gt = True\n",
    "                    for k in data_loader.items:\n",
    "                        if (data_loader.items[k][1] == items[j]):\n",
    "                            if data_loader.items[k][0] == 1:\n",
    "                                et = True\n",
    "                    heappush(scoreHeap, (1-score[j].cpu().numpy(), (0 + items[j].cpu().numpy(), gt)))\n",
    "                    heappush(ecoHeap, (1 - score[j].cpu().numpy(), (0 + items[j].cpu().numpy(), et)))\n",
    "                \n",
    "                scores = list()\n",
    "                ecoScores = list()\n",
    "                candidate = len(scoreHeap)\n",
    "                for k in range(candidate):\n",
    "                    scores.append(heappop(scoreHeap))\n",
    "                    ecoScores.append(heappop(ecoHeap))\n",
    "                pbar.update(1)\n",
    "                scoreDict[user[0]] = (scores, posItems.shape[1])\n",
    "                ecoDict[user[0]] = (ecoScores, posItems.shape[1])\n",
    "        pbar.close()\n",
    "        testResult = evaluation.ranking_performance(scoreDict, params['negNum_test'])\n",
    "        testResult = evaluation.ranking_performance(ecoDict, params['negNum_test'])\n",
    "#         with open('./results/'+category+'/'+category+'_PT_valResult_'+str(epoch)+'.json', 'w') as outfile:\n",
    "#             json.dump(testResult, outfile)\n",
    "print('starting test...')\n",
    "model.device = params['test_device']\n",
    "model.to(model.device)\n",
    "L = len(testLoader.dataset)\n",
    "pbar = tqdm(total=L, file=sys.stdout)\n",
    "with torch.no_grad():\n",
    "    scoreDict = dict()\n",
    "    ecoDict = dict()\n",
    "    for i, batchData in enumerate(testLoader):\n",
    "        user = torch.LongTensor(batchData['user']).to(model.device)\n",
    "        posItems = torch.LongTensor(batchData['posItem']).to(model.device)\n",
    "        negItems = torch.LongTensor(batchData['negItem']).to(model.device)\n",
    "\n",
    "        items = torch.cat((posItems, negItems), 1).view(-1)\n",
    "        users = user.expand(items.shape[0])\n",
    "        score = model.forward(users, items)\n",
    "        scoreHeap = list()\n",
    "        ecoHeap = list()\n",
    "        for j in range(score.shape[0]):\n",
    "            gt = False\n",
    "            et = False\n",
    "            if j < posItems.shape[1]:\n",
    "                gt = True\n",
    "            for k in data_loader.items:\n",
    "                if (data_loader.items[k][1] == items[j]):\n",
    "                    if data_loader.items[k][0] == 1:\n",
    "                        et = True\n",
    "            heappush(scoreHeap, (1-score[j].cpu().numpy(), (0+items[j].cpu().numpy(), gt)))\n",
    "            heappush(ecoHeap, (1 - score[j].cpu().numpy(), (0 + items[j].cpu().numpy(), et)))\n",
    "        scores = list()\n",
    "        ecoScores = list()\n",
    "        candidate = len(scoreHeap)\n",
    "        for k in range(candidate):\n",
    "            scores.append(heappop(scoreHeap))\n",
    "            ecoScores.append(heappop(ecoHeap))\n",
    "        pbar.update(1)\n",
    "        scoreDict[int(user[0].cpu().numpy())] = (scores, posItems.shape[1])\n",
    "        ecoDict[user[0]] = (ecoScores, posItems.shape[1])\n",
    "pbar.close()\n",
    "testResult = evaluation.ranking_performance(scoreDict, params['negNum_test'])\n",
    "testResult = evaluation.ranking_performance(ecoDict, params['negNum_test'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
